env:
  render_mode: 'human' # 'human' or 'rgb_array'
  environment: 'BipedalWalker-v3' # 'BipedalWalker-v3' or ...

trainer:
  no_episodes: 1000 # Number of episodes to run
  no_steps: 1000 # Number of steps per episode before stopping
  observation_memory_size: 5 # Number of observations to remember
  no_actions: 5 # Number of actions to take per step [1, 5]
  delay: 20 # Delay between steps (seconds)

  # To help determine token size to cut memory use
  observation_text_length : 1000 # Approx
  primer_length : 2500 # Approx

logger:
  save_dir: "G:/My Drive/UCSD/DSC/DSC190 - Few Labels/Assessing-Large-Language-Models-as-Agents-Evaluating-Responsiveness-and-Adaptability-in-Classic-Con/Bipedal Walker - Jack/runs" # Full path to save directory

experiment:
  type: 'enhanced' # 'baseline' or 'enhanced'
  no_check: 10 # Number of previous checks to use for enhanced
  threshold_rewards_no_change: 3 # Threshold for telling when there is no significant change in rewards
  threshold_leg_movement: 0.5 # Threshold for leg movement to tell when there is no significant change in leg movement
  llm: "gpt-4o-mini" # LLM model used [gpt-4o, gpt-4o-mini]